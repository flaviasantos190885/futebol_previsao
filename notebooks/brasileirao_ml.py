# -*- coding: utf-8 -*-
"""Brasileirao_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NrDC4XMrjup4Amx5ukPKlsLoDHBdBVdI

#Previsão Resultados Brasileirão Série A

##--- Instalações ---
"""

#--- Instalações ---
# !pip install pandas numpy plotly
# !pip install scikit-learn
# !pip install pycaret
# !pip install matplotlib seaborn
# !pip install -U pycaret[full] --quiet
# !pip install lightgbm
# !pip install catboost

"""## --- Importações ---"""

# --- Importações ---
# Certifique-se de que estas bibliotecas estão instaladas no seu ambiente:
# pip install pandas numpy pycaret scikit-learn imblearn
import pandas as pd
import numpy as np
import re
import unicodedata
from pycaret.classification import setup, create_model, tune_model, finalize_model, save_model, plot_model, predict_model

"""## --- Código ---"""

## --- Código ---

# Função para normalizar nomes de colunas
def slugify(text):
    text = unicodedata.normalize("NFKD", str(text)).encode("ascii", "ignore").decode("ascii")
    text = re.sub(r"[^0-9a-zA-Z]+", "_", text).strip("_").lower()
    return text

# --- Carregamento e Tratamento dos Dados ---
print("=============== Carregando e Tratando Dados ===============")

# Caminho do arquivo CSV
FILE_PATH = "competicoes_brasileirao_serie_a.csv" # Assumindo que este é o arquivo correto agora

try:
    df = pd.read_csv(FILE_PATH)
    df.columns = [slugify(col) for col in df.columns]
    print(f"Dados carregados com sucesso de: {FILE_PATH}")
    print(f"Shape inicial do DataFrame: {df.shape}")
    print("Primeiras 5 linhas do DataFrame:")
    print(df.head())
except FileNotFoundError:
    print(f"ERRO: O arquivo '{FILE_PATH}' não foi encontrado.")
    print("Por favor, verifique o caminho do arquivo.")
    exit()
except Exception as e:
    print(f"ERRO ao carregar o arquivo CSV: {e}")
    exit()

# Cria a coluna 'resultado' com base nos gols
if "resultado" not in df.columns:
    if "gols_mandante" in df.columns and "gols_visitante" in df.columns:
        # Garante que as colunas de gols são numéricas
        df["gols_mandante"] = pd.to_numeric(df["gols_mandante"], errors="coerce").fillna(0).astype(int)
        df["gols_visitante"] = pd.to_numeric(df["gols_visitante"], errors="coerce").fillna(0).astype(int)

        df["resultado"] = df.apply(
            lambda row: "Casa" if row["gols_mandante"] > row["gols_visitante"]
            else "Fora" if row["gols_mandante"] < row["gols_visitante"]
            else "Empate",
            axis=1
        )
    else:
        raise KeyError("As colunas 'gols_mandante' ou 'gols_visitante' não foram encontradas para gerar a coluna 'resultado'.")

# Remove linhas com resultado ausente ou inválido
df = df[df["resultado"].isin(["Casa", "Fora", "Empate"])].copy() # Usar .copy() para evitar SettingWithCopyWarning

# --- Lógica de Ajuste do Resultado para Desempate ---
print("\n=============== Aplicando Lógica de Desempate ===============")

# Calcular vitórias mandante (Casa) e visitante (Fora)
# Usar .groupby().size() é eficiente para contagem
vitorias_casa = df[df['resultado'] == 'Casa'].groupby('time_mandante').size()
vitorias_fora = df[df['resultado'] == 'Fora'].groupby('time_visitante').size()

def desempate(row):
    if row['resultado'] == 'Empate':
        mandante = row['time_mandante']
        visitante = row['time_visitante']
        # Usar .get() com valor padrão 0 para times que não aparecem nas vitórias
        casa_wins = vitorias_casa.get(mandante, 0)
        fora_wins = vitorias_fora.get(visitante, 0)

        if casa_wins > fora_wins:
            return 'Casa'
        elif fora_wins > casa_wins:
            return 'Fora'
        else:
            return 'Empate' # Mantém empate se o número de vitórias for igual
    else:
        return row['resultado']

# Aplica o ajuste e cria nova coluna 'resultado_ajustado'
df['resultado_ajustado'] = df.apply(desempate, axis=1)

print("Distribuição da coluna 'resultado' original:")
print(df['resultado'].value_counts())
print("\nDistribuição da coluna 'resultado_ajustado' após desempate:")
print(df['resultado_ajustado'].value_counts())


# Converter datas e extrair ano/mes
if "data" in df.columns:
    df["data"] = pd.to_datetime(df["data"], errors="coerce", dayfirst=True)
    df.dropna(subset=['data'], inplace=True) # Remover linhas com datas inválidas
    df["ano"] = df["data"].dt.year.astype(int)
    df["mes"] = df["data"].dt.month.astype(int)
else:
    print("AVISO: Coluna 'data' não encontrada. Usando ano=2023 e mes=1 como padrão.")
    df["ano"] = 2023
    df["mes"] = 1

# Tratamento de outliers em variáveis numéricas
# Aplicado apenas a colunas numéricas relevantes que não são IDs ou targets
num_cols_for_outliers = [
    'publico', 'colocacao_mandante', 'colocacao_visitante',
    'valor_equipe_titular_mandante', 'valor_equipe_titular_visitante',
    'idade_media_titular_mandante', 'idade_media_titular_visitante'
]

for col in num_cols_for_outliers:
    if col in df.columns and df[col].nunique() > 1 and pd.api.types.is_numeric_dtype(df[col]):
        # Converte para numérico antes de tratar outliers, lidando com possíveis não-numéricos
        df[col] = pd.to_numeric(df[col], errors='coerce')
        # Remove NaN temporariamente para calcular quartis, depois preenche
        temp_col = df[col].dropna()
        if not temp_col.empty:
            q1, q3 = temp_col.quantile([0.25, 0.75])
            iqr = q3 - q1
            if iqr > 0:
                lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr
                df[col] = np.clip(df[col], lower, upper)
            else:
                print(f"AVISO: IQR inválido (zero ou NaN) para a coluna '{col}'. Outliers não foram tratados.")
        else:
            print(f"AVISO: Coluna '{col}' está vazia após conversão para numérico. Não foi possível tratar outliers.")
    elif col in df.columns:
        print(f"AVISO: Coluna '{col}' não tratada para outliers (não numérica ou apenas um valor único).")
    else:
        print(f"AVISO: Coluna '{col}' não encontrada para tratamento de outliers.")

print(f"\nShape do DataFrame após tratamento: {df.shape}")
print("Verificação de valores nulos após tratamento:")
print(df.isnull().sum())

# --- Setup PyCaret ---
print("\n=============== Configurando Ambiente PyCaret ===============")

# Colunas a serem ignoradas pelo PyCaret
# 'data' (já extraímos ano/mes), 'gols_mandante', 'gols_visitante' (para evitar vazamento de dados),
# 'resultado' (usamos 'resultado_ajustado' como target),
# outras colunas que podem não ser features úteis ou que o modelo não deve ver.
ignore_features_list = [
    "data", "gols_mandante", "gols_visitante", "resultado",
    "ano_campeonato", "arbitro", "tecnico_mandante", "tecnico_visitante", "publico_max"
]
# Garante que apenas as colunas que realmente existem no df sejam ignoradas
ignore_features_existing = [col for col in ignore_features_list if col in df.columns]

try:
    exp = setup(
        data=df,
        target="resultado_ajustado",  # Usa a coluna ajustada como target
        session_id=42,
        fix_imbalance=False,
        remove_outliers=False,
        normalize=True,
        ignore_features=ignore_features_existing,
        verbose=True
    )
    print("\nAmbiente PyCaret configurado com sucesso!")
except Exception as e:
    print(f"ERRO ao configurar o ambiente PyCaret: {e}")
    print("Verifique se as colunas de dados estão corretas e se não há problemas de tipo.")
    exit()

# --- Comparação de Modelos ---
print("\n=============== Comparando Modelos de Classificação (PyCaret) ===============")
print("Isso pode levar alguns minutos...")

# Comparar todos os modelos de classificação disponíveis
best_model = compare_models(fold=5, sort='Accuracy') # Ordena por acurácia

print("\n\n=============== Melhor Modelo Encontrado Pelo PyCaret ===============")
print(best_model)

print("\n\n=============== Fim da Seleção de Modelo com PyCaret ===============\n")

## --- Salvar o modelo ---
save_model(final_model, "brasileirao_classificacao")
print("\nModelo 'brasileirao_classificacao.pkl' salvo com sucesso!")

# # Exporta dataset limpo (se quiser salvar a versão pré-processada)
df.to_csv("BRA_brasileirao_final.csv", index=False)

# # Matriz de confusão para validação visual (opcional, requer o modelo finalizado)
# # plot_model(final_model, plot="confusion_matrix")